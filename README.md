# M√©todos num√©ricos
Los m√©todos num√©ricos son aquellas t√©cnicas y algoritmos para resolver problemas matem√°ticos de manera aproximada utilizando c√°lculos num√©ricos y computacionales. Estos m√©todos son especialmente √∫tiles cuando no es posible obtener una soluci√≥n exacta o anal√≠tica utilizando m√©todos algebraicos o cuando los c√°lculos anal√≠ticos son demasiado complejos o costosos computacionalmente.

## Cifras significativas

### ¬øQu√© es?
Las cifras significativas son d√≠gitos de un n√∫mero que consideramos no nulos. **(No es lo mismo que cantidad de decimales)**.

### Objetivo
Cuando se emplea un n√∫mero para realizar un c√°lculo, debe haber seguridad de que pueda usarse con confianza. Las cifras significativas de un n√∫mero son aquellas que pueden utilizarse en forma confiable. Se trata del n√∫mero de d√≠gitos que se ofrecen con certeza, m√°s uno estimado.

A la omisi√≥n del resto de cifras significativas se le conoce como **error de redondeo**.

### Reglas pr√°cticas
- Los 0 a la derecha no definen una cantidad de C.S.
- Cualquier d√≠gito distinto de 0 es significativo
- Los 0 a la izquierda de la primera C.S no es significativo
- Los 0 entre d√≠gitos son significativos
- Si N > 1 entonces todos los 0 a la derecha son significativos
- Si N < 1 entonces solo los 0 al final y entre CS son significativos

## An√°lisis de errores
El t√©rmino error puede definirse como la inexactitud y/o imprecisi√≥n en las predicciones, en el supuesto de que conozcamos el valor verdadero al que queremos llegar los errores pueden definirse de la siguiente manera.
- Error absoluto: ![equation](https://latex.codecogs.com/svg.image?e&space;=&space;\left|&space;\widetilde{p}&space;-&space;p&space;\right|) 
- Error relativo: ![equation](https://latex.codecogs.com/svg.image?e&space;=&space;\left|&space;\frac{&space;\widetilde{p}&space;-&space;p&space;}{p}&space;\right|)
- Error porcentual: ![equation](https://latex.codecogs.com/svg.image?e&space;=&space;\left|&space;\frac{&space;\widetilde{p}&space;-&space;p&space;}{p}&space;\right|&space;\cdot&space;100)

donde ![equation](https://latex.codecogs.com/svg.image?\widetilde{p})  es una aproximaci√≥n del valor real
## An√°lisis de errores en m√©todos iterativos
En los m√©todos iterativos siempre vamos a hacer el supuesto de que el valor obtenido en la siguiente ejecuci√≥n ser√° una mejor aproximaci√≥n al valor real.
- Error absoluto: ![equation](https://latex.codecogs.com/svg.image?e&space;=&space;\left|&space;\widetilde{p}_{n&plus;1}&space;-&space;p_{n}&space;\right|)
- Error relativo: ![equation](https://latex.codecogs.com/svg.image?e&space;=&space;\left|&space;\frac{\widetilde{p}_{n&plus;1}&space;-&space;p_{n}}{\widetilde{p}_{n&plus;1}}&space;\right|)

### Criterio de parada
Una de las preguntas que surge cuando se emplean m√©todos iterativos, es: **¬øCu√°ndo es suficiente una aproximaci√≥n?** En ese sentido, siempre depender√° del contexto del problema. Sin embargo, nosotros definiremos un criterio conservador para obtener tantas cifras significativas.
En este caso diremos que **p** es una mejor aproximaci√≥n a **p** con **d** cifras significativas, si **d** es el mayor n√∫mero natural que verifique 


![equation](https://latex.codecogs.com/svg.image?E_{r}&space;=&space;\frac{\left|&space;\widetilde{p}&space;-&space;p&space;\right|}{\left|&space;\widetilde{p}&space;\right|}&space;\leq&space;0.5&space;\cdot&space;10^{-d})

## M√©todos cerrados
Son aquellos m√©todos que aprovechan el hecho de que una funci√≥n cambia de signo en la vecindad de una ra√≠z. A estas t√©cnicas se les llama m√©todos cerrados, o de intervalos, porque se necesita de dos valores iniciales para la ra√≠z. Como su nombre lo indica, dichos valores iniciales deben ‚Äúencerrar‚Äù, o estar a ambos lados de la ra√≠z.

<img src="https://i.imgur.com/E8sAHFA.png" alt="image" style="width:200px;height:200px;">

### M√©todo de bisecci√≥n
El m√©todo de bisecci√≥n es un m√©todo num√©rico utilizado para encontrar la ra√≠z de una funci√≥n en un intervalo dado. El m√©todo se basa en el teorema de Bolzano, que establece que si una funci√≥n es continua en un intervalo y los valores de la funci√≥n en los extremos del intervalo tienen signos opuestos, entonces existe al menos una ra√≠z en ese intervalo.

#### Criterio de parada
El error en el k-√©simo paso estar√° dado por la expresi√≥n 

![equation](https://latex.codecogs.com/svg.image?E_{relativo}&space;=&space;\frac{\left|&space;b_{original}&space;-&space;a_{original}&space;\right|}{2^{k}})

#### Predicci√≥n de bisecciones
Una de las ventajas de este m√©todo es que es posible predecir la cantidad de bisecciones a realizar para llegar a una determinada precisi√≥n mediante la f√≥rmula

![equation](https://latex.codecogs.com/svg.image?k&space;=&space;\left&space;[&space;\frac{ln(b&space;-&space;a)&space;-&space;ln(\alpha&space;)}{ln(2)}&space;\right&space;]) 

Donde ![equation](https://latex.codecogs.com/svg.image?\alpha) es la tolerancia

#### Algoritmo
1. Aseguramos que la funci√≥n f(x) sea continua en el intervalo [a, b]
2. Comprobamos que f(a) * f(b) < 0
3. Calculamos el punto medio "m" del intervalo [a, b]
4. El punto "m" debe evaluarse en la funci√≥n, si el valor es cero significa que hallamos la ra√≠z por el contrario, se redefine el intervalo [a, b] como [m, b] o [a, m] seg√∫n se haya determinado en cu√°l de estos intervalos ocurre el cambio de signo.
5. Con este nuevo intervalo se contin√∫a de manera sucesiva hasta "encerrar" la soluci√≥n en un intervalo cada vez m√°s peque√±o, hasta alcanzar la precisi√≥n deseada.

#### Desarrollo en Python
Para la funci√≥n  ![equation](https://latex.codecogs.com/svg.image?&space;f(x)&space;=&space;x^{2}&space;-&space;cos(x)&space;-&space;1)  en el intervalo [1, 2] con una precisi√≥n de cuatro cifras significativas

```python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return x**2 - np.cos(x) - 1
    
    # Establecemos el intervalo de la funci√≥n
    a = 1
    b = 2

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)

    # Estimamos la cantidad de bisecciones necesarias para aproximarse al resultado con tantas cifras significativas.
    def prediccion_de_bisecciones():
        return np.ceil((np.log(b-a) - np.log(cifras_significativas(4)))/np.log(2))
    
    # Comprobamos el teorema de bolzano en el intervalo
    if f(a) * f(b) < 0:
        print('Para aproximarse a la raiz con una tolerancia de ', cifras_significativas(4), ' se necesitaran ', prediccion_de_bisecciones(), ' bisecciones')
        biseccion = 1
        a_original = a
        b_original = b

        while True:
            # Definimos el punto medio del intervalo y el error.
            m = (a + b) / 2 
            error = (b_original - a_original)/2**biseccion

            # Si la funci√≥n evaluada en a tiene el mismo signo que la funci√≥n evaluada en m, entonces cambiamos a por m.        
            if f(a) * f(m) >= 0:
                a = m
            
            # Si la funci√≥n evaluada en b tiene el mismo signo que la funci√≥n evaluada en m, entonces cambiamos b por m.
            if f(b) * f(m) >= 0:
                b = m

            # Establecemos el criterio de parada
            if(error < cifras_significativas(4)):
                print("La raiz de la funcion es: ", m)
                break

            biseccion += 1
    else:
        print('El intervalo seleccionado no verifica el teorema de Bolzano')

if __name__ == '__main__':
    main()
```

### M√©todo de Regula Falsi
La falsa posici√≥n es una alternativa basada en una visualizaci√≥n gr√°fica. El hecho de que se reemplace la curva por una l√≠nea recta da una ‚Äúfalsa posici√≥n‚Äù de la ra√≠z; de aqu√≠ el nombre de m√©todo de la falsa posici√≥n, o en lat√≠n, regula falsi. Tambi√©n se le conoce como m√©todo de interpolaci√≥n lineal.

Mejora la convergencia del M√©todo de Bisecci√≥n, considerando no solo el signo de la funci√≥n en los extremos del intervalo, sino que aprovecha los valores de la imagen. Determina una recta que une los puntos (a, f(a)) y (b, f(b)) y fija el nuevo extremo c en la intersecci√≥n de dicha recta con el eje x.

Vamos a definir el punto "c" como:

![equation](https://latex.codecogs.com/svg.image?c&space;=&space;\frac{a&space;\cdot&space;f(b)&space;-&space;b&space;\cdot&space;f(a)}{f(b)&space;-&space;f(a)})

#### Criterio de parada
Para calcular el error utilizaremos la siguiente expresi√≥n

![equation](https://latex.codecogs.com/svg.image?E_{relativo}&space;=&space;\left|&space;{c_{nuevo}&space;-&space;c_{actual}}&space;\right|&space;<&space;\alpha&space;)

Donde ![equation](https://latex.codecogs.com/svg.image?\alpha) es la tolerancia

#### Algoritmo
1. Aseguramos que la funci√≥n f(x) sea continua en el intervalo [a, b]
2. Comprobamos que f(a) * f(b) < 0
3. Calculamos el punto "c" del intervalo [a, b]
4. El punto "c" debe evaluarse en la funci√≥n, si el valor es cero significa que hallamos la ra√≠z por el contrario, se redefine el intervalo [a, b] como [c, b] o [a, c] seg√∫n se haya determinado en cu√°l de estos intervalos ocurre el cambio de signo.
5. Con este nuevo intervalo se contin√∫a de manera sucesiva hasta "encerrar" la soluci√≥n en un intervalo cada vez m√°s peque√±o, hasta alcanzar la precisi√≥n deseada.

#### Desarrollo en Python
Para la funci√≥n  ![equation](https://latex.codecogs.com/svg.image?f(x)&space;=&space;x&space;\cdot&space;sen(x)&space;-&space;1)  en el intervalo [0, 2] con una precisi√≥n de cuatro cifras significativas

```python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return x * np.sin(x) - 1
    
    # Establecemos el intervalo de la funci√≥n
    a = 0
    b = 2

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)
    
    # Calculamos el punto "c"
    def calcular_c(a, b):
        return (a * f(b) - b * f(a))/(f(b) - f(a))
    
    # Comprobamos el teorema de bolzano en el intervalo
    if f(a) * f(b) < 0:
        c_actual = calcular_c(a, b)
        while True:
            # Si la funci√≥n evaluada en a tiene el mismo signo que la funci√≥n evaluada en c, entonces cambiamos a por c.        
            if f(a) * f(c_actual) >= 0:
                a = c_actual
            
            # Si la funci√≥n evaluada en b tiene el mismo signo que la funci√≥n evaluada en c, entonces cambiamos b por c.
            if f(b) * f(c_actual) >= 0:
                b = c_actual

            # Definimos el punto "c" nuevo del intervalo, el error y ahora ese c pasar√° a ser el actual.
            c_nuevo = calcular_c(a, b)
            error = np.abs(c_nuevo - c_actual)/c_nuevo
            c_actual = c_nuevo

            # Establecemos el criterio de parada
            if(error < cifras_significativas(4)):
                print("La raiz de la funcion es: ", c_actual)
                break
    else:
        print('El intervalo seleccionado no verifica el teorema de Bolzano')

if __name__ == '__main__':
    main()
```

## M√©todos abiertos
Son aquellos m√©todos que  se basan en f√≥rmulas que requieren √∫nicamente de un solo valor de inicio x o que empiecen con un par de ellos, pero que no necesariamente encierran la ra√≠z. √âstos, algunas veces divergen o se alejan de la ra√≠z verdadera a medida que se avanza en el c√°lculo. Sin embargo, cuando los m√©todos abiertos convergen, en general lo hacen mucho m√°s r√°pido que los m√©todos cerrados.

<img src="https://i.imgur.com/WdI6bqf.png" alt="image" style="width:200px;height:200px;">

### Iteraci√≥n de punto fijo
El m√©todo de iteraci√≥n de punto fijo implica tomar un valor inicial y aplicar repetidamente una f√≥rmula o funci√≥n espec√≠fica a ese valor para acercarse cada vez m√°s a la soluci√≥n deseada.

- Sea g: [a,b] -> R continuamente derivable, tal que g(x) pertenece a [a,b] para toda x perteneciente a [a,b]. Entonces, g tiene un punto fijo x* en [a,b]
- Si g'(x) existe en [a,b] y existe una constante positiva k < 1 con |g‚Ä≤(x)| ‚â§ k, para toda x perteneciente (a,b); entonces el punto fijo x* en [a,b] es √∫nico.
- Adem√°s, se puede acortar el error de la iteraci√≥n n-√©sima por (Para N > 2):


![equation](https://latex.codecogs.com/svg.image?\left|&space;x_{n}&space;-&space;x^{*}&space;\right|&space;\leq&space;\frac{k^{n}}{1&space;-&space;k}&space;\cdot&space;\left|&space;x_{1}&space;-&space;x_{2}\right|)


#### Comportamiento
En la pr√°ctica, si la derivada de g es continua, sucede que:
- Si: |g‚Äô(x)| > 1 entonces los iterados no convergen a x*
- Si: |g‚Äô(x)| < 1 entonces los iterados no convergen linealmente a x*
- Si: |g‚Äô(x)| = 1 entonces los iterados convergen cuadr√°ticamente a x*

#### Algoritmo
1. Hacer de f(x) = 0 a x = g(x) mediante un desarrollo algebraico. Esta ecuaci√≥n se puede ‚Äúacomodar‚Äù de varias maneras por lo tanto vamos a tener varios x = g(x).
2. Derivar las g(x) y evaluar en todas, la semilla. Para obtener una semilla se puede resolver la desigualdad ‚àí1 ‚â§ g‚Ä≤(x) ‚â§ 1. Analizar la convergencia seg√∫n la tabla anterior. Tambi√©n se puede analizar el gr√°fico y ver el cambio de signo de la funci√≥n
3. Establecer un criterio de parada

#### Desarrollo en Python
Para la funci√≥n ![equation](https://latex.codecogs.com/svg.image?&space;f(x)=e^x-4&plus;x&space;) con una ra√≠z en [1, 2] con una precisi√≥n de ![equation](https://latex.codecogs.com/svg.image?\varepsilon_r<10^-2)

```python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return (np.exp(1) ** x) - 4 + x
    
    # Convertimos f(x) a x = g(x)
    # Opci√≥n 1
    def g(x):
        return 4 - (np.exp(1) ** x)
    
    # Opci√≥n 2
    def h(x):
        return (np.exp(1) ** x) - 4 + 2 * x
    
    # Opci√≥n 3
    def j(x):
        return np.log(4 - x)
    
    # Establecemos el intervalo de la funci√≥n
    a = 1
    b = 2

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)
    
    def punto_fijo(funcion, x0, tolerancia, max_iter):
        x = x0
        iteraciones = 0
        
        while iteraciones < max_iter:
            x_nueva = funcion(x)
            
            # Verificamos el criterio de parada
            if np.abs(x_nueva - x) < tolerancia:
                return x_nueva, iteraciones
            
            x = x_nueva
            iteraciones += 1
        
        raise ValueError('El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.')
    
    # Aplicamos el m√©todo de punto fijo a la funci√≥n j(x)
    x0 = 1
    tolerancia = cifras_significativas(2)
    max_iter = 10
    
    try:
        raiz, iteraciones = punto_fijo(j, x0, tolerancia, max_iter)
        print(f"Ra√≠z: {raiz}")
        print(f"N√∫mero de iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()
```

### M√©todo de Newton - Raphson
Esta t√©cnica es una versi√≥n mejorada del m√©todo del punto fijo y es bastante popular. Se destaca por avanzar m√°s r√°pido hacia la ra√≠z, a veces duplicando la cantidad de d√≠gitos exactos en cada intento, siempre y cuando se cumplan ciertas condiciones.

Hablando de manera sencilla, partiendo de una estimaci√≥n Xn‚Äã, para la siguiente aproximaci√≥n Xn+1‚Äã, simplemente seguimos la tangente de la curva hasta que cruza el eje x en el punto (Xn, Xn+1). 

#### Algoritmo
1. Seleccionar un punto inicial x0‚Äã cerca de la ra√≠z.
2. En cada iteraci√≥n, calcula el valor Xn+1 con la f√≥rmula:
![equation](https://latex.codecogs.com/svg.image?&space;x_{nueva}=x_{anterior}-\frac{f(x_{anterior})}{f'(x_{anterior})})

#### Desarrollo en Python
Para la funci√≥n ![equation](https://latex.codecogs.com/svg.image?x^2-cos(x)-1) con una ra√≠z en [1, 2] con una precisi√≥n de ![equation](https://latex.codecogs.com/svg.image?\varepsilon_r<10^-5)

```python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return (np.exp(1) ** x) - 4 + x
    
    # Convertimos f(x) a x = g(x)
    # Opci√≥n 1
    def g(x):
        return 4 - (np.exp(1) ** x)
    
    # Opci√≥n 2
    def h(x):
        return (np.exp(1) ** x) - 4 + 2 * x
    
    # Opci√≥n 3
    def j(x):
        return np.log(4 - x)
    
    # Establecemos el intervalo de la funci√≥n
    a = 1
    b = 2

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)
    
    def punto_fijo(funcion, x0, tolerancia, max_iter):
        x = x0
        iteraciones = 0
        
        while iteraciones < max_iter:
            x_nueva = funcion(x)
            
            # Verificamos el criterio de parada
            if np.abs(x_nueva - x) < tolerancia:
                return x_nueva, iteraciones
            
            x = x_nueva
            iteraciones += 1
        
        raise ValueError('El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.')
    
    # Aplicamos el m√©todo de punto fijo a la funci√≥n j(x)
    x0 = 1
    tolerancia = cifras_significativas(2)
    max_iter = 10
    
    try:
        raiz, iteraciones = punto_fijo(j, x0, tolerancia, max_iter)
        print(f"Ra√≠z: {raiz}")
        print(f"N√∫mero de iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()
```

### M√©todo de la secante
Hay funciones cuyas derivadas son un verdadero dolor de cabeza para calcular, ah√≠ es donde entra en juego este m√©todo (¬°No se necesita calcular derivadas!). 

Este m√©todo necesita dos valores iniciales de x. Sin embargo, no es necesario que la funci√≥n f(x) cambie de signo entre esos dos valores. Por eso, no lo llamamos un m√©todo cerrado.

#### Algoritmo
1. Seleccionar dos valores iniciales x0‚Äã y x1‚Äã que est√©n cerca de la ra√≠z.
2. Evaluar la funci√≥n en f(x0) y f(x1)
3. Calcular la pendiente m con

![equation](https://latex.codecogs.com/svg.image?\frac{f(x_1)-f(x_0)}{x_1-x_0})

4. Calcular el nuevo valor de x con la f√≥rmula:

![equation](https://latex.codecogs.com/svg.image?x_{nueva}=x_{1}-\frac{f(x_{1})}{m})

#### Desarrollo en Python
Para la funci√≥n ![equation](https://latex.codecogs.com/svg.image?x^2-cos(x)-1) con una ra√≠z en [-1, -2] con una precisi√≥n de ![equation](https://latex.codecogs.com/svg.image?\varepsilon_r<10^-5)

```python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return (x**2) - np.cos(x) - 1
    
    def derivada_f(x):
        return 2*x + np.sin(x)
    
    # Establecemos el intervalo de la funci√≥n
    a = 1
    b = 2

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)
    
    def newton_raphson(funcion, derivada, x0, tolerancia, max_iter):
        x = x0
        iteraciones = 0
        
        while iteraciones < max_iter:
            x_nueva = x - funcion(x) / derivada(x)
            
            # Verificamos el criterio de parada
            if np.abs(x_nueva - x) < tolerancia:
                return x_nueva, iteraciones
            
            x = x_nueva
            iteraciones += 1
        
        raise ValueError("El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.")
    
    # Aplicamos el m√©todo de Newton Raphson a f(x)
    x0 = 1.5
    try:
        raiz, iteraciones = newton_raphson(f, derivada_f, x0, cifras_significativas(5), 10)
        print(f"Ra√≠z encontrada: {raiz}")
        print(f"Iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()
```

## Dos m√©todos especiales
Adem√°s de los m√©todos que hemos programado en el repositorio, existen otras dos alternativas especiales para hallar las ra√≠ces de un polinomio, estos son:

- El m√©todo de M√ºller
- El m√©todo de Bairstow


### M√©todo de M√ºller
El m√©todo de Muller es un m√©todo num√©rico que se asemeja al m√©todo de la secante, que aproxima una ra√≠z mediante una l√≠nea recta trazada entre dos puntos. En el caso del m√©todo de Muller, en lugar de utilizar dos puntos, se emplean tres puntos para construir una par√°bola. 
La par√°bola se ajusta de manera que pase por los tres puntos iniciales, y se determinan los coeficientes de la par√°bola.

<img src="https://i.imgur.com/Rzq3Fy7.jpg" alt="image" style="width:100%;height:100%;">

#### Algoritmo
1. Evaluar la funci√≥n en tres puntos cercanos a la ra√≠z 
2. Calcular los siguientes valores

![equation](https://latex.codecogs.com/svg.image?h_{0}=x_{1}-x_{0})

![equation](https://latex.codecogs.com/svg.image?h_{1}=x_{12}-x_{1})

![equation](https://latex.codecogs.com/svg.image?d_0=\frac{f(x_1)-f(x_0)}{h_0})

![equation](https://latex.codecogs.com/svg.image?d_1=\frac{f(x_2)-f(x_1)}{h_1})

![equation](https://latex.codecogs.com/svg.image?d=\frac{d_1-d_0}{h_0&plus;h_1)

![equation](https://latex.codecogs.com/svg.image?b=d\cdot&space;h1&plus;d_1)

![equation](https://latex.codecogs.com/svg.image?D=\sqrt{b^2-4\cdot&space;f(x_2)\cdot&space;d})


3. Realizar las siguientes comparaciones

Si | b - D | < | b + D |, entonces: E = b + D

Si | b - D | > | b + D |, entonces: E = b - D

4. Calcular h, x3 y la tolerancia

![equation](https://latex.codecogs.com/svg.image?h=\frac{-2\cdot&space;f(x_2)}{E})

![equation](https://latex.codecogs.com/svg.image?x_3=x_2&plus;h)

![equation](https://latex.codecogs.com/svg.image?\left|h\right|)

5. Realizar la siguiente iteraci√≥n con

x3 -> x2

x2 -> x1

x1 -> x0

#### Desarrollo en Python
Para la funci√≥n ![equation](https://latex.codecogs.com/svg.image?&space;x^3-13x-12) con los valores iniciales x0, x1 y x2 = 4,5; 5,5 y 5 con una precisi√≥n de ![equation](https://latex.codecogs.com/svg.image?\varepsilon_r<10^-5)

```Python
import numpy as np

def main():
    # Definimos la funci√≥n para la cual queremos aproximar la ra√≠z
    def f(x):
        return (x**3) - (13*x) - 12

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)
    
    def muller(funcion, x0, x1, x2, tolerancia, max_iter):
        h0 = x1 - x0
        h1 = x2 - x1
        d0 = (funcion(x1) - funcion(x0)) / h0
        d1 = (funcion(x2) - funcion(x1)) / h1
        d = (d1 - d0) / (h0 + h1)
        
        iteraciones = 0
        while iteraciones < max_iter:
            b = (h1 * d) + d1
            D = np.sqrt(b**2 - 4*funcion(x2)*d)
            
            if np.abs(b - D) < np.abs(b + D):
                E = b + D
            else:
                E = b - D
            
            h = (-2 * funcion(x2)) / E
            x3 = x2 + h
            
            if np.abs(h) < tolerancia:
                return x3, iteraciones
            
            x0 = x1
            x1 = x2
            x2 = x3
            
            h0 = x1 - x0
            h1 = x2 - x1
            d0 = (funcion(x1) - funcion(x0)) / h0
            d1 = (funcion(x2) - funcion(x1)) / h1
            d = (d1 - d0) / (h0 + h1)
            
            iteraciones += 1
        
        raise ValueError("El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.")

    # Aplicamos el m√©todo de Muller a f(x)
    x0 = 4.5
    x1 = 5.5
    x2 = 5
    
    try:
        raiz, iteraciones = muller(f, x0, x1, x2, cifras_significativas(5), 10)
        print(f"Ra√≠z encontrada: {raiz}")
        print(f"Iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()
```

### M√©todo de Bairstow
El M√©todo de Bairstow es un algoritmo iterativo utilizado para encontrar las ra√≠ces de polinomios de segundo o mayor grado. Este m√©todo es especialmente eficiente para polinomios con coeficientes reales y complejos.
La idea principal detr√°s del M√©todo de Bairstow es realizar una factorizaci√≥n cuadr√°tica sucesiva del polinomio original, reduci√©ndolo gradualmente hasta que se obtengan las ra√≠ces finales. Se inicia con una suposici√≥n de las ra√≠ces y luego se ajustan iterativamente para obtener una mejor aproximaci√≥n.

#### Algoritmo

1. Se tiene una ecuaci√≥n de la forma ![equation](https://latex.codecogs.com/svg.image?f_{n}(x)=a_0&plus;a_1x&plus;a_2x^{2}&plus;...&plus;a_nx^n)

2. Se divide entre el factor x - t, residuo R = B0

3. Se calculan los coeficientes

![equation](https://latex.codecogs.com/svg.image?b_n=a_n&space;)

![equation](https://latex.codecogs.com/svg.image?b_{n-1}=a_{n-1}&plus;rb_{n})

![equation](https://latex.codecogs.com/svg.image?b_{i}=a_{i}&plus;rb_{i&plus;1}&plus;sb_{i&plus;2}) para i = n - 2 a 0

![equation](https://latex.codecogs.com/svg.image?c_n=b_n)

![equation](https://latex.codecogs.com/svg.image?c_{n-1}=b_{n-1}&plus;rc_n)

![equation](https://latex.codecogs.com/svg.image?c_{i}=b_{i}&plus;rc_{i&plus;1}&plus;sc_{i&plus;2}) para i = n - 2 a 1

4. Se reemplazan estos datos en las ecuaciones

![equation](https://latex.codecogs.com/svg.image?c_2\Delta&space;r&plus;c_3\Delta&space;s=-b_1)

![equation](https://latex.codecogs.com/svg.image?c_1\Delta&space;r&plus;c_2\Delta&space;s=-b_0)

5. Despejando r y s

![equation](https://latex.codecogs.com/svg.image?\Delta&space;r=\frac{c_3&space;b_0-c_2&space;b_1}{c_2^2-c_1&space;c_3})

![equation](https://latex.codecogs.com/svg.image?\Delta&space;s=\frac{c_1&space;b_1-c_2&space;b_0}{c_2^2-c_1&space;c_3})

6. Se corrigen los nuevos valores de r y s

7. Se eval√∫a el erorr aproximado

8. Se obtienen los valores de las ra√≠ces

![equation](https://latex.codecogs.com/svg.image?x=\frac{r\pm\sqrt{r^2&plus;4s}}{2})

#### Desarrollo en Python
Para la funci√≥n  ![equation](https://latex.codecogs.com/svg.image?&space;x^5-3.5x^4&plus;2.75x^3&plus;2.125x^2-3.875x&plus;1.25) utilizando los valores r = s = -1 iterando hasta e = 1%

```Python
import numpy as np

def main():
    def bairstow(coeficientes, r, s, tolerancia, max_iter):
        n = len(coeficientes) - 1
        iteraciones = 0

        while iteraciones < max_iter:
            # Inicializamos las variables
            b = np.zeros(n + 1)
            c = np.zeros(n + 1)

            # Calculamos los dos primeros valores para b y c
            b[n] = coeficientes[0]
            b[n - 1] = coeficientes[1] + (r) * b[n]
            c[n] = b[n]
            c[n - 1] = b[n - 1] + r * c[n]

            # Calculamos el resto de valores
            for i in range(2, n + 1):
                b[n - i] = coeficientes[i] + (r) * b[n - i + 1] + s * b[n - i + 2]
                c[n - i] = b[n - i] + (r) * c[n - i + 1] + s * c[n - i + 2]

            # Resolvemos las ecuaciones de r y s
            deltaR = ((c[n - 2] * b[n - 5]) - (c[n - 3] * b[n - 4])) / ((c[n - 3]**2) - (c[n - 4] * c[n - 2]))
            deltaS = ((c[n - 4] * b[n - 4]) - (c[n - 3] * b[n - 5])) / ((c[n - 3]**2) - (c[n - 4] * c[n - 2]))
            r = r + deltaR 
            s = s + deltaS

            errorR = np.abs(deltaR / r) * 100
            errorS = np.abs(deltaS / s) * 100

            # Verificamos el criterio de parada
            if errorR < tolerancia and errorS < tolerancia:
                # Calculamos las ra√≠ces
                x1 = (r + np.sqrt((r**2) + 4 * s)) / 2
                x2 = (r - np.sqrt((r**2) + 4 * s)) / 2
                return r, s, x1, x2 

            iteraciones += 1

        raise ValueError("El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.")

    # Aplicamos el m√©todo de Bairstow a f(x)
    coeficientes = [1, -3.5, 2.75, 2.125, -3.875, 1.25]
    r = -1
    s = -1

    try:
        r, s, x1, x2 = bairstow(coeficientes, r, s, 1, 10)
        print(f"r encontrado: {r}")
        print(f"s encontrado: {s}")
        print(f"Ra√≠ces encontradas: x1 = {x1}, x2 = {x2}")
    except ValueError as e:
        print(e)
        
if __name__ == '__main__':
    main()
```

## Sistema de ecuaciones lineales
Los sistemas de ecuaciones lineales son conjuntos de ecuaciones en las que cada ecuaci√≥n es una funci√≥n lineal de las mismas variables. Estos sistemas se puede representar de la siguiente manera:

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e7a71b074b0bd4839735fb1a3a6990ef81f91d2" alt="image">

donde x1, x2, ‚Ä¶, xn‚Äã son las variables desconocidas, Aij‚Äã son los coeficientes constantes, y Bi‚Äã son los t√©rminos constantes en cada ecuaci√≥n. Este sistema tiene m ecuaciones y n variables. Estos sistemas se pueden resolver para encontrar los valores de las variables desconocidas que satisfacen todas las ecuaciones simult√°neamente.

## Matrices
Un sistema de ecuaciones lineales se puede representar de manera matricial, lo que facilita su an√°lisis y resoluci√≥n. Por ejemplo, el siguiente sistema de ecuaciones lineales con dos inc√≥gnitas, x e y:

<img src="https://latex.codecogs.com/svg.image?\left\{\begin{matrix}a_{11}x&a_{12}y&=&b_{1}\\a_{21}x&a_{22}y&=&b_{2}\\\end{matrix}\right." alt="image">

Se puede representar en forma matricial definiendo la matriz de coeficientes A, el vector de inc√≥gnitas X, y el vector de t√©rminos constantes B de la siguiente manera:

<img src="https://latex.codecogs.com/svg.image?A=\begin{pmatrix}a_{11}&b_{12}\\a_{21}&b_{22}\\\end{pmatrix}" alt="image">

<img src="https://latex.codecogs.com/svg.image?X=\begin{pmatrix}x\\y\end{pmatrix}" alt="image">

<img src="https://latex.codecogs.com/svg.image?B=\begin{pmatrix}b_{1}\\b_{2}\end{pmatrix}" alt="image">

Entonces, el sistema de ecuaciones se puede expresar de forma compacta como 

<img src="https://latex.codecogs.com/svg.image?A\cdot&space;X=B" alt="image">

Por lo tanto, la soluci√≥n del sistema se encuentra multiplicando ambos lados de la ecuaci√≥n por la inversa de la matriz A

<img src="https://latex.codecogs.com/svg.image?X=A^{-1}\cdot&space;B&space;" alt="image">

### Operaciones matriciales
completar

### Tipos especiales de matrices cuadradas
Hay diferentes formas especiales de matrices cuadradas que son importantes y que deben mencionarse

#### Matriz sim√©trica
Es aquella donde 

![equation](https://latex.codecogs.com/svg.image?&space;a_{ij}=a_{ji}) 

para todo i y j. Por ejemplo:

<img src="https://latex.codecogs.com/svg.image?\left[A\right]=\begin{pmatrix}5&1&2\\1&3&7\\2&7&8\\\end{pmatrix}" alt="image">

#### Matriz diagonal
Una matriz diagonal es una matriz cuadrada donde todos los elementos fuera de la diagonal principal son iguales a cero

<img src="https://latex.codecogs.com/svg.image?\left[A\right]=\begin{pmatrix}a_{11}&&&\\&a_{22}&&\\&&a_{33}&\\&&&a_{44}\\\end{pmatrix}" alt="image">

#### Matriz identidad
Una matriz identidad es una matriz diagonal donde todos los elementos sobre la diagonal principal son iguales a 1

<img src="https://latex.codecogs.com/svg.image?\left[I\right]=\begin{pmatrix}1&&&\\&1&&\\&&1&\\&&&1\\\end{pmatrix}" alt="image">

#### Matriz triangular superior
Es aquella donde todos los elementos por debajo de la diagonal principal son cero

<img src="https://latex.codecogs.com/svg.image?\left[A\right]=\begin{pmatrix}a_{11}&a_{12}&a_{13}&a_{14}\\&a_{22}&a_{23}&a_{24}\\&&a_{33}&a_{34}\\&&&a_{44}\\\end{pmatrix}" alt="image">

#### Matriz triangular inferior
Es aquella donde todos los elementos por arriba de la diagonal principal son cero

<img src="https://latex.codecogs.com/svg.image?\left[A\right]=\begin{pmatrix}a_{11}&&&\\a_{21}&a_{22}&&\\a_{31}&a_{32}&a_{33}&\\a_{41}&a_{42}&a_{43}&a_{44}\\\end{pmatrix}" alt="image">

#### Matriz bandeada
Es aquella que tiene todos los elementos iguales a cero, con la excepci√≥n de una banda centrada sobre la diagonal principal

<img src="https://latex.codecogs.com/svg.image?\left[A\right]=\begin{pmatrix}a_{11}&a_{12}&&\\a_{21}&a_{22}&a_{23}&\\&a_{32}&a_{33}&a_{34}\\&&a_{43}&a_{44}\\\end{pmatrix}" alt="image">

### Normas vectoriales
Una norma vectorial es una funci√≥n que asigna a cada vector en un espacio vectorial un n√∫mero real no negativo. La norma de un vector v, generalmente denotada como ‚à•v‚à•, satisface algunas propiedades espec√≠ficas, como la homogeneidad positiva, la desigualdad triangular y la identidad del tri√°ngulo

#### Norma valor absoluto
Suponiendo el vector V = (1; 3; -5; 2)

![equation](https://latex.codecogs.com/svg.image?\left\|x\right\|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|=1&plus;3&plus;5&plus;2=11) 

#### Norma euclidea
Suponiendo el vector V = (1; 3; -5; 2)

![equation](https://latex.codecogs.com/svg.image?\left\|x\right\|_{2}=\sqrt{\left(\sum_{i=1}^{n}x_{i}^2\right)}=\sqrt{1^2&plus;3^2&plus;5^2&plus;2^2}=\sqrt{39}) 

#### Norma m√°xima o infinita
Suponiendo el vector V = (1; 3; -5; 2)

![equation](https://latex.codecogs.com/svg.image?\left\|x\right\|_{\infty}=max\left|x_{i}\right|i=1,...,n=max\begin{Bmatrix}1;3;-5;2\end{Bmatrix}=5) 

### Normas matriciales
Al igual que con los vectores, las matrices tambi√©n pueden tener asociadas diversas normas que miden de alguna manera su tama√±o o magnitud

#### Norma fila o infinito
Teniendo en cuenta la matriz 

<img src="https://latex.codecogs.com/svg.image?A=\begin{pmatrix}1&2&3\\4&5&0\\-1&2&-3\\\end{pmatrix}" alt="image">

<img src="https://imgur.com/735aowG.png" alt="image">

#### Norma columna
<img src="https://latex.codecogs.com/svg.image?A=\begin{pmatrix}1&2&3\\4&5&0\\-1&2&-3\\\end{pmatrix}" alt="image">

<img src="https://imgur.com/0x2YAh9.png" alt="image">

#### Norma Frobenius
<img src="https://latex.codecogs.com/svg.image?A=\begin{pmatrix}1&2&3\\4&5&0\\-1&2&-3\\\end{pmatrix}" alt="image">

<img src="https://imgur.com/IeZYhQA.png" alt="image">

## M√©todos directos
Los m√©todos directos para resolver sistemas de ecuaciones lineales (SEL) son algoritmos que encuentran la soluci√≥n exacta del sistema en un n√∫mero finito de pasos. Estos m√©todos proporcionan una soluci√≥n √∫nica y no requieren una suposici√≥n inicial, los m√©todos m√°s comunes son:

* Sustituci√≥n
* Reducci√≥n
* Igualaci√≥n
* M√©todo de Gauss
* M√©todo de Gauss - Jordan
* Regla de Cramer
* M√©todo de la matriz inversa

Estos m√©todos son eficientes para sistemas de ecuaciones lineales de tama√±o peque√±o o moderado y son especialmente √∫tiles cuando se necesita una soluci√≥n exacta. Sin embargo, la complejidad computacional de estos m√©todos puede aumentar significativamente con el tama√±o del sistema.
En este caso, optaremos por no enfocarnos en los m√©todos directos para la resoluci√≥n de sistemas de ecuaciones lineales. En lugar de eso, dirigiremos nuestra atenci√≥n hacia los m√©todos indirectos o iterativos.

## M√©todos indirectos
Los m√©todos indirectos, tambi√©n conocidos como m√©todos iterativos, son t√©cnicas utilizadas para resolver problemas matem√°ticos mediante la repetici√≥n de un proceso de aproximaci√≥n sucesiva. A diferencia de los m√©todos directos, que buscan obtener una soluci√≥n exacta en un n√∫mero finito de pasos, los m√©todos iterativos mejoran continuamente la aproximaci√≥n a la soluci√≥n mediante la repetici√≥n de un conjunto de operaciones.
En este contexto, centraremos nuestra atenci√≥n en dos m√©todos iterativos ampliamente utilizados para resolver sistemas de ecuaciones lineales: el M√©todo de Jacobi y el M√©todo de Gauss-Seidel. 

### M√©todo de Jacobi
Este m√©todo es particularmente √∫til cuando se trata de sistemas lineales de gran tama√±o. Desarrollado por el matem√°tico alem√°n Carl Gustav Jacob Jacobi, este m√©todo aborda la resoluci√≥n de sistemas de ecuaciones al descomponer la matriz de coeficientes en la suma de una matriz diagonal y dos matrices triangulares. 

#### Algoritmo 
Es decir: la matriz A es la suma de tres matrices: una matriz diagonal D, y dos matrices triangulares L y U. La descomposici√≥n se expresa como A = D + L + U, donde:

* D es la matriz diagonal que contiene los elementos diagonales de A
* L es la matriz triangular inferior con los elementos fuera de la diagonal de A
* U es la matriz triangular superior con los elementos fuera de la diagonal de A

Entonces:

1. Se distribuye x

![equation](https://latex.codecogs.com/svg.image?(L&plus;D&plus;U)\cdot&space;x=b)  

2. Se despeja x y se utiliza por conveniencia a la diagonal

![equation](https://latex.codecogs.com/svg.image?Lx&plus;Dx&plus;Ux=b) 

3. Se multiplica por la inversa de la diagonal

![equation](https://latex.codecogs.com/svg.image?Dx=(-L-U)x&plus;b) 

![equation](https://latex.codecogs.com/svg.image?x=D^{-1}(-L-U)x&plus;D^{-1}&plus;b) 

5. Se renombran las variables

![equation](https://latex.codecogs.com/svg.image?T=D^{-1}(-L-U)) 

![equation](https://latex.codecogs.com/svg.image?C=D^{-1}b) 

6. Por lo tanto

![equation](https://latex.codecogs.com/svg.image?x=Tx&plus;C) 

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos el sistema de ecuaciones
    A = np.array([[3, -1, -1],
                  [-1, 3, 1],
                  [2, 1, 4]])

    b = np.array([1, 3, 7])

    # Establecemos el criterio de parada (norma infinito en este caso)
    def criterio_parada(x, x_prev, tolerancia):
        return np.linalg.norm(x - x_prev, np.inf) < tolerancia

    def metodo_jacobi(A, b, x0, tolerancia, max_iter):
        n = len(b)
        x = x0.copy()
        x_prev = x0.copy()
        iteraciones = 0

        while iteraciones < max_iter:
            for i in range(n):
                sigma = np.dot(A[i, :n], x_prev[:n]) + np.dot(A[i, n:], x_prev[n:])
                x[i] = (b[i] - sigma + A[i, i] * x_prev[i]) / A[i, i]

            # Verificamos el criterio de parada
            if criterio_parada(x, x_prev, tolerancia):
                return x, iteraciones

            x_prev = x.copy()
            iteraciones += 1

        raise ValueError("El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.")

    # Aplicamos el m√©todo de Jacobi al sistema de ecuaciones
    x0 = np.zeros_like(b, dtype=float)
    try:
        solucion, iteraciones = metodo_jacobi(A, b, x0, 0.000001, 100)
        print("Soluci√≥n encontrada:")
        print(solucion)
        print(f"Iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()

```

### M√©todo de Gauss - Seidel
El m√©todo de Gauss-Seidel es un algoritmo iterativo utilizado para resolver sistemas de ecuaciones lineales. Este m√©todo lleva el nombre de los matem√°ticos Carl Friedrich Gauss y Philipp Ludwig von Seidel. A diferencia del m√©todo de Jacobi, el m√©todo de Gauss - Seidel actualiza las soluciones de las ecuaciones en el mismo orden en el que aparecen en el sistema.

La idea principal del m√©todo de Gauss-Seidel es realizar actualizaciones sucesivas de las soluciones de las ecuaciones, utilizando los valores m√°s recientes disponibles. En cada iteraci√≥n, las nuevas soluciones se utilizan de inmediato en las siguientes ecuaciones del sistema, lo que puede conducir a una convergencia m√°s r√°pida en comparaci√≥n con el m√©todo de Jacobi.

Este m√©todo es particularmente eficaz para sistemas en los que la matriz de coeficientes es diagonalmente dominante o sim√©trica y definida positiva, adem√°s de esta forma se garantiza la convergencia. No obstante, el m√©todo puede funcionar, aunque no se satisfagan estos criterios.

#### Algoritmo

1. Si los elementos de la diagonal no son todos cero, la primera ecuaci√≥n se puede resolver para x1, la segunda para x2 y la tercera para x3, para obtener:

![equation](https://latex.codecogs.com/svg.image?x_{1}=\frac{b_{1}-a_{12}x_{2}-a_{13}x_{3}}{a_{11}}) 

![equation](https://latex.codecogs.com/svg.image?x_{2}=\frac{b_{2}-a_{21}x_{1}-a_{23}x_{3}}{a_{22}}) 

![equation](https://latex.codecogs.com/svg.image?x_{3}=\frac{b_{3}-a_{31}x_{1}-a_{32}x_{2}}{a_{33}}) 

2. Se puede empezar el proceso de soluci√≥n al escoger valores iniciales para las x. Una forma simple para obtener los valores iniciales es suponer que todos son cero, estos se sustituyen en la ecuaci√≥n:

![equation](https://latex.codecogs.com/svg.image?x_{1}=\frac{b_{1}-a_{12}x_{2}-a_{13}x_{3}}{a_{11}}) 

3. Con el valor obtenido para X1, se sustituye junto con el valor previo cero de x3 en la ecuaci√≥n

![equation](https://latex.codecogs.com/svg.image?x_{2}=\frac{b_{2}-a_{21}x_{1}-a_{23}x_{3}}{a_{22}}) 

4. Se calcula el nuevo valor de X2, y se repite el proceso con la ecuaci√≥n para calcular un nuevo valor de X3.

![equation](https://latex.codecogs.com/svg.image?x_{3}=\frac{b_{3}-a_{31}x_{1}-a_{32}x_{2}}{a_{33}}) 

5. Luego se regresa a la primera ecuaci√≥n y se repite  todo el procedimiento hasta que la soluci√≥n converja suficientemente cerca a los valores verdaderos.

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos el sistema de ecuaciones
    A = np.array([
        [9, 2, -1],
        [7, 8, 5],
        [3, 4, -10]
    ])

    b = np.array([-2, 3, 6])

    # Establecemos el criterio de parada
    def cifras_significativas(d):
        return (1/2) * (10**-d)

    def gauss_seidel(A, b, x0, tolerancia, max_iter):
        n = len(b)
        x = x0.copy()
        iteraciones = 0

        while iteraciones < max_iter:
            x_prev = x.copy()

            for i in range(n):
                suma1 = np.dot(A[i, :i], x[:i])
                suma2 = np.dot(A[i, i + 1:], x_prev[i + 1:])
                x[i] = (b[i] - suma1 - suma2) / A[i, i]

            # Verificamos el criterio de parada (Norma infinito vs. cantidad de cifras significativas requeridas)
            if np.linalg.norm(x - x_prev, np.inf) < tolerancia:
                return x, iteraciones

            iteraciones += 1

        raise ValueError("El m√©todo no converge en el n√∫mero m√°ximo de iteraciones.")

    # Aplicamos el m√©todo de Gauss-Seidel al sistema de ecuaciones
    x0 = np.zeros_like(b, dtype=float)
    try:
        solucion, iteraciones = gauss_seidel(A, b, x0, cifras_significativas(5), 100)
        print("Soluci√≥n encontrada:")
        print(solucion)
        print(f"Iteraciones: {iteraciones}")
    except ValueError as e:
        print(e)

if __name__ == '__main__':
    main()
```

## Integraci√≥n num√©rica

La integraci√≥n num√©rica es una herramienta que se utiliza para obtener valores aproximados de integrales definidas que no pueden calcularse anal√≠ticamente. El objetivo es aproximar la integral definida de una funci√≥n ùëì(x) en un intervalo [a, b] evaluando ùëì(x) en un n√∫mero finito de puntos.

### Cuadratura num√©rica
En esta secci√≥n se estudian t√©cnicas para la aproximaci√≥n de integrales cuyas primitivas no siempre pueden calcularse aplicando el teorema fundamental del c√°lculo, especialmente sobre funciones que no tienen primitiva elemental. El m√©todo b√°sico para resolver este tipo de integrales se conoce como cuadratura num√©rica.

![equation](https://latex.codecogs.com/svg.image?\int_{a}^{b}f(x)d(x)=\sum_{i=1}^{n}w_{i}\cdot&space;f(x_{i})&plus;E(f^{(n)}))

<img src="https://i.imgur.com/3qqYMUc.png" alt="image" style="width:200px;height:200px;">

### F√≥rmula de Newton - Cotes
Las f√≥rmulas de Newton-Cotes son los tipos de integraci√≥n num√©rica m√°s comunes. Se basan en la estrategia de reemplazar una funci√≥n complicada o datos tabulados por un polinomio de interpolaci√≥n que es f√°cil de integrar.

### Regla del trapecio
Esta regla se deduce a partir de la resoluci√≥n de la integral aplicada sobre el polinomio de grado uno de Lagrange

![equation](https://latex.codecogs.com/svg.image?\int_{a}^{b}f(x)d(x)=\frac{h}{2}\cdot(f(x_{0})&plus;f(x_{1}))-\frac{h^{3}}{12}f''(\varepsilon))

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos la funci√≥n a integrar
    def f(x):
        return 1 + np.exp(1) ** -x * np.sin(4*x)

    # Definimos los l√≠mites de integraci√≥n
    a = 0
    b = 1

    # Aplicamos la regla del trapecio para calcular la integral
    integral = regla_del_trapecio(f, a, b)
    print("Valor aproximado de la integral: ", integral)

def regla_del_trapecio(f, a, b):
    h = (b - a) / 2
    integral = h * (f(a) + f(b)) 
    return integral

if __name__ == '__main__':
    main()
```

### Regla de Simpson
Esta regla se deduce a partir de la resoluci√≥n de la integral aplicada sobre el polinomio de segundo grado de Lagrange

![equation](https://latex.codecogs.com/svg.image?\int_{a}^{b}f(x)d(x)=\frac{h}{3}\cdot(f(x_{0})&plus;4\cdot&space;f(x_{1})&plus;f(x_{2}))-\frac{h^{5}}{90}f^{(4)}(\varepsilon))

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos la funci√≥n a integrar
    def f(x):
        return 1 + np.exp(1) ** -x * np.sin(4*x)

    # Definimos los l√≠mites de integraci√≥n
    a = 0
    b = 1

    # Aplicamos la regla de Simpson para calcular la integral
    integral = regla_de_Simpson(f, a, b)
    print("Valor aproximado de la integral:", integral)

def regla_de_Simpson(f, a, b):
    h = (b - a) / 2
    c = (a + b) / 2
    integral = (h / 3) * (f(a) + 4 * f(c) + f(b))
    return integral

if __name__ == '__main__':
    main()
```

### Regla de Simpson 3/8
Esta regla se deduce a partir de la resoluci√≥n de la integral aplicada sobre el polinomio de tercer grado de Lagrange

![equation](https://latex.codecogs.com/svg.image?\int_{a}^{b}f(x)d(x)=\frac{3h}{8}\cdot(f(x_{0})&plus;3\cdot&space;f(x_{1})&plus;3\cdot&space;f(x_{2})&plus;f(x_{3}))-\frac{3h^5}{80}f^{(6)}(\xi))

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos la funci√≥n a integrar
    def f(x):
        return 1 + np.exp(1) ** -x * np.sin(4*x)

    # Definimos los l√≠mites de integraci√≥n
    a = 0
    b = 1

    # Aplicamos la regla 3/8 de Simpson para calcular la integral
    integral = regla_38_Simpson(f, a, b)
    print("Valor aproximado de la integral:", integral)

def regla_38_Simpson(f, a, b):
    h = (b - a) / 3
    c = (2*a + b) / 3
    d = (a + 2*b) / 3
    integral = (3 * h / 8) * (f(a) + 3 * f(c) + 3 * f(d) + f(b))
    return integral

if __name__ == '__main__':
    main()
```

### Regla de Boole
Esta regla se deduce a partir de la resoluci√≥n de la integral aplicada sobre el polinomio de cuarto grado de Lagrange

![equation](https://latex.codecogs.com/svg.image?\int_{a}^{b}f(x)d(x)=\frac{2h}{45}\cdot(7\cdot&space;f(x_{0})&plus;32\cdot&space;f(x_{1})&plus;12\cdot&space;f(x_{2})&plus;32\cdot&space;f(x_{3})&plus;7\cdot&space;f(x_{4}))-\frac{8h^5}{945}f^{(6)}(\xi))

#### Desarrollo en Python
```python
import numpy as np

def main():
    # Definimos la funci√≥n a integrar
    def f(x):
        return 1 + np.exp(1) ** -x * np.sin(4*x)

    # Definimos los l√≠mites de integraci√≥n
    a = 0
    b = 1

    # Aplicamos la regla de Boole para calcular la integral
    integral = regla_de_Boole(f, a, b)
    print("Valor aproximado de la integral:", integral)

def regla_de_Boole(f, a, b):
    h = (b - a) / 4
    c = a + h
    d = a + 2 * h
    e = a + 3 * h
    integral = (2 * h / 45) * (7 * f(a) + 32 * f(c) + 12 * f(d) + 32 * f(e) + 7 * f(b))
    return integral

if __name__ == '__main__':
    main()
```


## Bibliograf√≠a
- Chapra, S. C., & Canale, R. P. (2010). M√©todos num√©ricos para ingenieros (5a ed.). M√©xico: McGrawHill.